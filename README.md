# YOLOv8 ile GerÃ§ek ZamanlÄ± Video AkÄ±ÅŸÄ±nda Ä°nsan SayÄ±mÄ± ve YoÄŸunluk Tespiti
Bu proje, bir video akÄ±ÅŸÄ± Ã¼zerinden **YOLOv8 nano (yolov8n) modeli** kullanarak gerÃ§ek zamanlÄ± insan tespiti, takibi ve sayÄ±mÄ± yapar. Tespit edilen nesneleri gÃ¶rselleÅŸtirerek, her karedeki anlÄ±k insan sayÄ±sÄ±nÄ±, videodaki toplam benzersiz insan sayÄ±sÄ±nÄ± ve insan yoÄŸunluÄŸunu hesaplayarak Ã§Ä±ktÄ± video olarak kaydeder. Temel amacÄ±mÄ±z, video iÃ§erisindeki insan varlÄ±ÄŸÄ±nÄ± hÄ±zlÄ± ve etkili bir ÅŸekilde tespit etmek, takip etmek ve bu sÃ¼reci anlaÅŸÄ±lÄ±r bir ÅŸekilde gÃ¶rselleÅŸtirmektir.
> Proje, Python dilinde geliÅŸtirilmiÅŸ olup, gÃ¼Ã§lÃ¼ nesne algÄ±lama ve takip kÃ¼tÃ¼phanelerini kullanmaktadÄ±r.
---
## Ä°Ã§indekiler
- [Proje AmacÄ±](#proje-amacÄ±)
- [Proje Ã–zellikleri](#proje-Ã¶zellikleri)
- [YOLOv8 Nano Model Nedir?](#yolov8-nano-model-nedir)
- [ByteTrack KÃ¼tÃ¼phanesi Nedir?](#bytetrack-kÃ¼tÃ¼phanesi-nedir)
- [KullanÄ±lan Teknolojiler](#kullanÄ±lan-teknolojiler)
- [Kurulum](#kurulum)
- [KullanÄ±m](#kullanÄ±m)
- [Ã–rnek GÃ¶rseller](#tespit-Ã¶rneÄŸi-gÃ¶rselleri)
---
## Proje AmacÄ±
Bu projenin temel amacÄ±, **YOLOv8 nano (yolov8n)** gibi modern bir derin Ã¶ÄŸrenme modelini ve **ByteTrack** gibi bir nesne takip algoritmasÄ±nÄ± kullanarak gerÃ§ek dÃ¼nya video akÄ±ÅŸlarÄ±nda insan tespiti, takibi ve sayÄ±mÄ± yeteneÄŸini sergilemektir. Ã–zellikle:
* **GerÃ§ek ZamanlÄ± Ä°nsan Tespiti ve Takibi:** Video kareleri Ã¼zerinde yÃ¼ksek performansla insanlarÄ± algÄ±lamak ve benzersiz ID'lerle takip etmek.
* **Ä°nsan SayÄ±mÄ±:** Her bir karedeki anlÄ±k insan sayÄ±sÄ±nÄ± ve tÃ¼m video boyunca gÃ¶rÃ¼nen toplam benzersiz insan sayÄ±sÄ±nÄ± hesaplamak.
* **KalabalÄ±k YoÄŸunluÄŸu Tespiti:** Tespit edilen insan sayÄ±sÄ±na gÃ¶re video alanÄ±ndaki yoÄŸunluÄŸu tahmin etmek.
* **GÃ¶rselleÅŸtirme:** Tespit edilen nesnelerin Ã¼zerine sÄ±nÄ±r kutularÄ±, etiketler ve sayÄ±m bilgileri Ã§izerek algÄ±lama ve takip sonuÃ§larÄ±nÄ± anlaÅŸÄ±lÄ±r kÄ±lmak.
* **Uygulama AlanlarÄ±:** GÃ¼venlik, trafik analizi, kalabalÄ±k yÃ¶netimi, perakende analizi gibi Ã§eÅŸitli alanlarda temel bir altyapÄ± sunmak.
---
## Proje Ã–zellikleri
- Belirtilen video dosyasÄ±ndan **kareleri okuma ve iÅŸleme**.
- **YOLOv8 nano modeli** ile video akÄ±ÅŸÄ±nda **gerÃ§ek zamanlÄ± insan tespiti** (sadece `person` sÄ±nÄ±fÄ±).
- **ByteTrack** algoritmasÄ± ile tespit edilen insanlarÄ± benzersiz kimliklerle **takip etme**.
- Her karede **anlÄ±k insan sayÄ±sÄ±nÄ±** ve tÃ¼m video boyunca gÃ¶rÃ¼nen **toplam benzersiz insan sayÄ±sÄ±nÄ±** hesaplama.
- Videodaki insan **yoÄŸunluÄŸunu** (piksel baÅŸÄ±na dÃ¼ÅŸen insan sayÄ±sÄ±) hesaplama.
- Tespit edilen nesnelerin Ã¼zerine **sÄ±nÄ±r kutularÄ± (bounding boxes)**, etiketler (sÄ±nÄ±f adÄ±, gÃ¼ven skoru, takip ID) Ã§izme.
- Ekran Ã¼zerinde **anlÄ±k sayÄ±m ve toplam sayÄ±m bilgilerini** gÃ¶rselleÅŸtirme.
- Ä°ÅŸlenmiÅŸ video akÄ±ÅŸÄ±nÄ± yeni bir **MP4 dosyasÄ±na kaydetme**.
- SaÄŸlam **hata yÃ¶netimi** ve kaynak yÃ¶netimi (video okuma/yazma).
---
## YOLOv8 Nano Model Nedir?
**YOLO (You Only Look Once)**, gerÃ§ek zamanlÄ± nesne algÄ±lama alanÄ±nda devrim niteliÄŸinde bir derin Ã¶ÄŸrenme modelidir. Geleneksel yÃ¶ntemlerin aksine, gÃ¶rÃ¼ntÃ¼yÃ¼ tek bir geÃ§iÅŸte iÅŸleyerek hem nesnelerin konumunu hem de sÄ±nÄ±flarÄ±nÄ± tahmin eder, bu da onu oldukÃ§a hÄ±zlÄ± yapar.
![YoloV8n YapÄ±sÄ±](img/yolov8n.png)
<small>(source: https://www.mdpi.com/2076-3417/14/17/7686)</small>
**YOLOv8 nano (`yolov8n.pt`) modeli** ise YOLOv8 serisinin en kÃ¼Ã§Ã¼k ve en hÄ±zlÄ± varyantÄ±dÄ±r. Daha az parametreye sahip olmasÄ± ve daha az hesaplama gÃ¼cÃ¼ gerektirmesi sayesinde, **dÃ¼ÅŸÃ¼k kaynaklÄ± cihazlarda veya gerÃ§ek zamanlÄ± uygulamalarda yÃ¼ksek performans** sunar. Boyutuna raÄŸmen, hala etkileyici bir doÄŸrulukla nesneleri tespit edebilir. Bu projenin hÄ±zlÄ± ve pratik bir Ã§Ã¶zÃ¼m sunabilmesi iÃ§in ideal bir seÃ§imdir.
---
## ByteTrack KÃ¼tÃ¼phanesi Nedir?
**ByteTrack**, yÃ¼ksek performanslÄ± ve doÄŸru Ã§oklu nesne takibi iÃ§in tasarlanmÄ±ÅŸ modern bir takip algoritmasÄ±dÄ±r. Ã–zellikle nesnelerin geÃ§ici olarak kaybolduÄŸu veya Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼ durumlarda bile saÄŸlam takip yeteneÄŸiyle Ã¶ne Ã§Ä±kar. DÃ¼ÅŸÃ¼k gÃ¼ven skoruna sahip tespitleri bile deÄŸerlendirerek, nesne kimliklerinin daha uzun sÃ¼re korunmasÄ±na yardÄ±mcÄ± olur ve bu sayede sayÄ±m gibi uygulamalarda daha doÄŸru sonuÃ§lar elde edilmesini saÄŸlar. Projemizde insan sayÄ±mÄ± iÃ§in bu kÃ¼tÃ¼phanenin takip yeteneklerinden faydalanÄ±yoruz.
---
## KullanÄ±lan Teknolojiler
-   **Python:** Temel programlama dili.
-   **YOLOv8:** GerÃ§ek zamanlÄ± nesne algÄ±lama modeli (Ã¶zellikle `yolov8n.pt` nano modeli).
-   **OpenCV (`cv2`):** Video okuma, yazma ve temel gÃ¶rÃ¼ntÃ¼ iÅŸleme operasyonlarÄ± iÃ§in gÃ¼Ã§lÃ¼ bir kÃ¼tÃ¼phane.
-   **Supervision:** Nesne algÄ±lama ve takip sonuÃ§larÄ±nÄ± kolayca gÃ¶rselleÅŸtirmek iÃ§in (sÄ±nÄ±r kutularÄ±, etiketleme ve ByteTrack entegrasyonu) kullanÄ±lan modern bir kÃ¼tÃ¼phane.
-   **Ultralytics:** YOLOv8 modelinin kullanÄ±mÄ± ve eÄŸitimi iÃ§in temel kÃ¼tÃ¼phane.
-   **ByteTrack:** YÃ¼ksek performanslÄ± ve doÄŸru nesne takibi iÃ§in kullanÄ±lan algoritma.
---
## Kurulum
Projeyi yerel makinenizde Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin:
1.  **Python OrtamÄ± OluÅŸturma:** Python 3.8 veya Ã¼zeri yÃ¼klÃ¼ olduÄŸundan emin olun. BaÄŸÄ±mlÄ±lÄ±k Ã§akÄ±ÅŸmalarÄ±nÄ± Ã¶nlemek iÃ§in bir **sanal ortam** kullanmanÄ±z ÅŸiddetle tavsiye edilir:
    ```bash
    python -m venv venv
    # Linux/macOS iÃ§in sanal ortamÄ± etkinleÅŸtirin:
    source venv/bin/activate
    # Windows iÃ§in sanal ortamÄ± etkinleÅŸtirin:
    .\venv\Scripts\activate
    ```
2.  **BaÄŸÄ±mlÄ±lÄ±klarÄ±n YÃ¼klenmesi:** Gerekli tÃ¼m Python kÃ¼tÃ¼phanelerini `pip` kullanarak yÃ¼kleyin:
    ```bash
    pip install opencv-python ultralytics supervision
    ```
3.  **Model AÄŸÄ±rlÄ±klarÄ±nÄ±n Ä°ndirilmesi:** YOLOv8 nano model aÄŸÄ±rlÄ±klarÄ± (`yolov8n.pt`), ilk Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda Ultralytics kÃ¼tÃ¼phanesi tarafÄ±ndan otomatik olarak indirilecektir. Ä°nternet baÄŸlantÄ±nÄ±zÄ±n olduÄŸundan emin olun.
---
## KullanÄ±m
## Proje YapÄ±sÄ±
Projenin temel dizin ve dosya yapÄ±sÄ± aÅŸaÄŸÄ±daki gibidir:
````
.
â”œâ”€â”€ pose_classification/
â”‚Â Â  â”œâ”€â”€ dataset/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ action_log_simple.json
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ audrey.mp4
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ best_action_model.h5
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ label_encoder.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ man.mp4
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ person_actions_log.csv
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ test01.mp4
â”‚Â Â  â”‚Â Â  â””â”€â”€ test02.mp4
â”‚Â Â  â”œâ”€â”€ extract_keypoints_from_videos.py
â”‚Â Â  â”œâ”€â”€ improved_multiperson_detection...
â”‚Â Â  â”œâ”€â”€ multiperson_detection.py
â”‚Â Â  â”œâ”€â”€ pose_detection.py
â”‚Â Â  â”œâ”€â”€ real_time_prediction.py
â”‚Â Â  â”œâ”€â”€ train_classifier.py
â”‚Â Â  â””â”€â”€ yolov8n.pt
â”œâ”€â”€ pose_estimation/
â”‚Â Â  â”œâ”€â”€ images/
â”‚Â Â  â”‚Â Â  â””â”€â”€ (Ã¶rnek gÃ¶rseller)
â”‚Â Â  â”œâ”€â”€ pose_estimation.py
â”‚Â Â  â””â”€â”€ realtime_pe.py
â””â”€â”€ README.md
````

1.  Ä°ÅŸlemek istediÄŸiniz video dosyasÄ±nÄ± projenizin ana dizinindeki `xxx.mp4` yoluna yerleÅŸtirin. (Alternatif olarak, kod iÃ§erisindeki `video_path` deÄŸiÅŸkenini kendi video dosyanÄ±zÄ±n yolu ile gÃ¼ncelleyebilirsiniz.)
    **Video KaynaÄŸÄ± Ã–nerisi:** Kendi videolarÄ±nÄ±z yoksa veya farklÄ± insan videolarÄ±yla deneme yapmak isterseniz, telifsiz ve yÃ¼ksek kaliteli insan videolarÄ±nÄ± [Pexels Video KÃ¼tÃ¼phanesi](https://www.pexels.com/search/videos/human/) Ã¼zerinden edinebilirsiniz.
ben Kaggele Ã¼zerinden aÅŸaÄŸÄ±daki linkten verileri elde ettim :
https://www.kaggle.com/datasets/sharjeelmazhar/human-activity-recognition-video-dataset/data
2.  Ana Python betiÄŸini Ã§alÄ±ÅŸtÄ±rÄ±n (betiÄŸinizin adÄ± Ã¶rneÄŸin `main_counting_script.py` ise):
    ```bash
    python main_counting_script.py
    ```
3.  Ä°ÅŸlem tamamlandÄ±ÄŸÄ±nda, algÄ±lanan insanlarÄ±, Ã§izilen sÄ±nÄ±r kutularÄ±nÄ±, takip ID'lerini ve sayÄ±m bilgilerini iÃ§eren Ã§Ä±ktÄ± videosu, projenin `output/street_detection.mp4` konumunda bulunacaktÄ±r. Konsolda ayrÄ±ca toplam benzersiz kiÅŸi sayÄ±sÄ± yazdÄ±rÄ±lacaktÄ±r.
---
## Tespit Ã–rneÄŸi GÃ¶rselleri
### ğŸ“Œ 1. Pose Estimation
AÅŸaÄŸÄ±daki gÃ¶rselde yalnÄ±zca tek bir karede (fotoÄŸrafta) iskelet Ã§Ä±karÄ±mÄ± yapÄ±lmÄ±ÅŸtÄ±r:
<p>
  <img src="images/1.png" alt="Orijinal" width="45%" style="margin-right: 5%;">
  <img src="images/2.png" alt="Pose Estimation - Tennis" width="45%">
</p>


### ğŸ“Œ 2. Pose Classification (Real-time)
Bu gÃ¶rselde ise videodan alÄ±nan keypoint'ler ile "clapping" hareketi baÅŸarÄ±yla sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸtÄ±r:
<p>
  <img src="images/4.png" alt="Orijinal" width="45%" style="margin-right: 5%;">
  <img src="images/3.png" alt="Pose Classification" width="45%">
</p>
